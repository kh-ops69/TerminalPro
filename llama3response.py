import ollama

# template is for consistent format of response generation
template = """**AI Assistant:** {response}

**Additional Notes:** (Optional - Add specific notes based on user input or error messages)
"""

# system prompt is for general instructions to llm
system = """You are a helpful AI assistant specializing in assisting users with terminal commands.

You will explain the purpose and functionality of commands when requested.

You will provide guidance and troubleshooting assistance to users who encounter difficulties while executing commands.

To effectively help users, you will analyze their command history and the error messages generated by previously executed commands.
"""

def get_response(input, template, sys_prompt=system):
    response = ollama.chat(
    model="llama3.1",
    messages=[
        {
            "role": "user",
            "content": input,
        },
        {
            "role": "system",
            "content": sys_prompt,
        },
    ],
)
    response_text = response["message"]["content"]
    formatted_response = template.format(response=response_text)
    return formatted_response